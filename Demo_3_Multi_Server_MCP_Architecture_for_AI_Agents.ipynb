{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNsA04sN16wNSjiKzVQOyrn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dipanjanS/building-effective-agentic-ai-systems-dhs2025/blob/main/Demo_3_Multi_Server_MCP_Architecture_for_AI_Agents.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "![](https://i.imgur.com/ztInM2d.png)"
      ],
      "metadata": {
        "id": "2ATQg77SXso_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Installing Dependencies"
      ],
      "metadata": {
        "id": "SSax2dz0L_Ks"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L2Uwy5SFgMGc",
        "outputId": "f331a436-5037-4e79-ffcc-1b0b36fb7e13"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m687.6 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.7/43.7 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.6/70.6 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m152.5/152.5 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.8/158.8 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.9/43.9 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.6/50.6 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.2/45.2 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m216.5/216.5 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install langchain==0.3.27 langchain-openai==0.3.30 langgraph==0.6.5 langchain-mcp-adapters==0.1.9 mcp==1.12.4 --quiet"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Building a MCP Server for the Finance Department\n",
        "\n",
        "This section defines a **FastMCP** server named `FinanceServer` that runs on **port `8010`** and is started with **`mcp.run(transport=\"streamable-http\")`**.\n",
        "\n",
        "It registers two tools via `@mcp.tool()`:\n",
        "\n",
        "- `generate_invoice(customer_id: str) -> dict`  \n",
        "  Returns a stubbed invoice payload, e.g.  \n",
        "  `{\"invoice_id\": \"INV-1001\", \"customer_id\": \"<id>\", \"amount\": 2500, \"status\": \"generated\"}`\n",
        "\n",
        "- `get_budget_summary(department: str) -> dict`  \n",
        "  Returns a simple budget snapshot, e.g.  \n",
        "  `{\"department\": \"<dept>\", \"budget\": 100000, \"spent\": 65432, \"remaining\": 34568}`\n",
        "\n",
        "The server’s `FastMCP(...)` constructor includes a short instruction string and the explicit port.\n"
      ],
      "metadata": {
        "id": "ZFBqXmzUG1sG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile finance_mcp_server.py\n",
        "\n",
        "from mcp.server.fastmcp import FastMCP\n",
        "\n",
        "# Server with instructions\n",
        "mcp = FastMCP(\n",
        "    name=\"FinanceServer\",\n",
        "    instructions=\"\"\"\n",
        "        This server provides finance-related tools.\n",
        "        - Call generate_invoice(customer_id) to generate a new invoice for a customer.\n",
        "        - Call get_budget_summary(department) to retrieve the budget overview of any department.\n",
        "    \"\"\",\n",
        "    port=8010\n",
        ")\n",
        "\n",
        "@mcp.tool()\n",
        "def generate_invoice(customer_id: str) -> dict:\n",
        "    return {\n",
        "        \"invoice_id\": \"INV-1001\",\n",
        "        \"customer_id\": customer_id,\n",
        "        \"amount\": 2500,\n",
        "        \"status\": \"generated\"\n",
        "    }\n",
        "\n",
        "@mcp.tool()\n",
        "def get_budget_summary(department: str) -> dict:\n",
        "    return {\n",
        "        \"department\": department,\n",
        "        \"budget\": 100000,\n",
        "        \"spent\": 65432,\n",
        "        \"remaining\": 34568\n",
        "    }\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"Starting Finance MCP Server...\")\n",
        "    mcp.run(transport=\"streamable-http\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eCj6N0LRgSMy",
        "outputId": "f415e199-58a0-4e40-b20f-7f8252e30277"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing finance_mcp_server.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Deploying the MCP Server for the Finance Department\n",
        "\n",
        "The Finance server is launched as a background process in the notebook server:\n",
        "- Starts FinanceServer on ` http://localhost:8010/mcp` using the `streamable-http` transport.\n",
        "- Logs are written to `finance_server_output.log`.\n"
      ],
      "metadata": {
        "id": "sr9bchkOG5-i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nohup python /content/finance_mcp_server.py > finance_server_output.log 2>&1 &"
      ],
      "metadata": {
        "id": "iZ0kGm1Fgr7b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "![](https://i.imgur.com/8n4J8qV.png)"
      ],
      "metadata": {
        "id": "rojrlRCvH2P5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Building a MCP Server for the HR Department\n",
        "\n",
        "This section defines a **FastMCP** server named `HRServer` that runs on **port `8011`** and is started with **`mcp.run(transport=\"streamable-http\")`**.\n",
        "\n",
        "It registers two tools via `@mcp.tool()`:\n",
        "\n",
        "- `get_employee_details(employee_id: str) -> dict`  \n",
        "  Returns a stubbed employee profile, e.g.  \n",
        "  `{\"employee_id\": \"<id>\", \"name\": \"Alice Johnson\", \"role\": \"Software Engineer\", \"department\": \"Tech\"}`\n",
        "\n",
        "- `check_leave_balance(employee_id: str) -> dict`  \n",
        "  Returns leave information, e.g.  \n",
        "  `{\"employee_id\": \"<id>\", \"leave_balance\": 12}`\n",
        "\n",
        "Like the Finance server, `FastMCP(...)` includes instructions and the explicit port.\n"
      ],
      "metadata": {
        "id": "4IhPSbCJH-TS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile hr_mcp_server.py\n",
        "\n",
        "from mcp.server.fastmcp import FastMCP\n",
        "\n",
        "# Server with instructions\n",
        "mcp = FastMCP(\n",
        "    name=\"HRServer\",\n",
        "    instructions=\"\"\"\n",
        "        This server provides human resources tools.\n",
        "        - Call get_employee_details(employee_id) to fetch an employee's information.\n",
        "        - Call check_leave_balance(employee_id) to view the available leave balance for an employee.\n",
        "    \"\"\",\n",
        "    port=8011\n",
        ")\n",
        "\n",
        "@mcp.tool()\n",
        "def get_employee_details(employee_id: str) -> dict:\n",
        "    return {\n",
        "        \"employee_id\": employee_id,\n",
        "        \"name\": \"Alice Johnson\",\n",
        "        \"role\": \"Software Engineer\",\n",
        "        \"department\": \"Tech\"\n",
        "    }\n",
        "\n",
        "@mcp.tool()\n",
        "def check_leave_balance(employee_id: str) -> dict:\n",
        "    return {\n",
        "        \"employee_id\": employee_id,\n",
        "        \"leave_balance\": 12\n",
        "    }\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"Starting HR MCP Server...\")\n",
        "    mcp.run(transport=\"streamable-http\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c0l-JSZ4gj4X",
        "outputId": "e0f7479a-e9b5-40fc-a8fe-f79fa16a24d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting hr_mcp_server.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Deploying the MCP Server for the HR Department\n",
        "\n",
        "The HR server is launched as a background process in the notebook server:\n",
        "- Starts HRServer on ` http://localhost:8011/mcp` using the `streamable-http` transport.\n",
        "- Logs are written to `hr_server_output.log`."
      ],
      "metadata": {
        "id": "NCUR5DbkIC8C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nohup python /content/hr_mcp_server.py > hr_server_output.log 2>&1 &"
      ],
      "metadata": {
        "id": "-VD8sib7gxPX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "![](https://i.imgur.com/sHdQjL9.png)"
      ],
      "metadata": {
        "id": "lgNvm75GIU6t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Building the Client Agent\n",
        "\n",
        "This section creates a client agent that connects to both servers:\n",
        "\n",
        "- **MCP client:**  \n",
        "  ```python\n",
        "  client = MultiServerMCPClient({\n",
        "      \"finance\": {\"url\": \"http://localhost:8010/mcp\", \"transport\": \"streamable_http\"},\n",
        "      \"hr\":      {\"url\": \"http://localhost:8011/mcp\", \"transport\": \"streamable_http\"}\n",
        "  })\n",
        "  ```\n",
        "- **LLM:**  \n",
        "  ```python\n",
        "  llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
        "  ```\n",
        "\n",
        "- **Tool discovery:**  \n",
        "  ```python\n",
        "  tools = await client.get_tools()\n",
        "  print(\"Discovered tools:\", [tool.name for tool in tools])\n",
        "  ```\n",
        "\n",
        "- **Agent:**  \n",
        "  ```python\n",
        "  agent = create_react_agent(model=llm, tools=tools)\n",
        "  ```\n",
        "\n",
        "This setup produces a single agent capable of invoking tools from **both** `FinanceServer` and `HRServer` using MCP."
      ],
      "metadata": {
        "id": "uhQSBs_lL3yV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile client_agent.py\n",
        "\n",
        "from langchain_mcp_adapters.client import MultiServerMCPClient\n",
        "from langgraph.prebuilt import create_react_agent\n",
        "from langchain_openai import ChatOpenAI\n",
        "import asyncio\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "load_dotenv()\n",
        "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
        "\n",
        "async def main():\n",
        "    client = MultiServerMCPClient({\n",
        "        \"finance\": {\n",
        "            \"url\": \"http://localhost:8010/mcp\",\n",
        "            \"transport\": \"streamable_http\"\n",
        "        },\n",
        "        \"hr\": {\n",
        "            \"url\": \"http://localhost:8011/mcp\",\n",
        "            \"transport\": \"streamable_http\"\n",
        "        }\n",
        "    })\n",
        "\n",
        "    tools = await client.get_tools()\n",
        "    print(\"Discovered tools:\", [tool.name for tool in tools])\n",
        "\n",
        "    agent = create_react_agent(model=llm, tools=tools)\n",
        "\n",
        "    # Sample queries\n",
        "    print('\\nUsing capabilities from Finance - Invoice Generation:')\n",
        "    result_1 = await agent.ainvoke({\"messages\": [{\"role\": \"user\", \"content\": \"Can you generate an invoice for customer 123?\"}]})\n",
        "    print(result_1['messages'][-1].content)\n",
        "\n",
        "    print('\\nUsing capabilities from HR - Leave Balance:')\n",
        "    result_2 = await agent.ainvoke({\"messages\": [{\"role\": \"user\", \"content\": \"Show me the leave balance for employee 456\"}]})\n",
        "    print(result_2['messages'][-1].content)\n",
        "\n",
        "    print('\\nUsing capabilities from Finance - Budget Planning:')\n",
        "    result_3 = await agent.ainvoke({\"messages\": [{\"role\": \"user\", \"content\": \"What is the tech department’s budget summary?\"}]})\n",
        "    print(result_3['messages'][-1].content)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    asyncio.run(main())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pHzw5OrJg2HS",
        "outputId": "4cbbbcfe-71a4-4cce-f810-b0373db40ba7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting client_agent.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Running the Client Agent"
      ],
      "metadata": {
        "id": "fNpvWRVuL7Sj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![](https://i.imgur.com/S2vfh6c.png)"
      ],
      "metadata": {
        "id": "GdLm3Ssn_G8-"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eMt4NX0YL1J0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}